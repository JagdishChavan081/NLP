{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Web Scrapping and Analyzing Data From Tweeter</h3></center> \n",
    "<center><h5>code by:Jagdish Chavan</h5><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NLP:Task** Scrape and Analyze tweets(minimum 1,000 tweets) for anyone Zomato/Swiggy/Amazon/Flipkart\n",
    "\n",
    "* Aim: with Python and NLP perform tweeter scraping and analyze the data \n",
    "\n",
    "* Requirements:\n",
    "    * For this task I decided to build virtual environment with help of Anaconda\n",
    "    * IDE: Jupyter Notebook\n",
    "    * Python =3.9\n",
    "    * Libraries \n",
    "        * Tweepy:Tweepy is an open source Python package that gives you a very convenient way to access the Twitter API with Python\n",
    "\n",
    "\n",
    "        \n",
    "* For scrapping purpose you will require security keys, 4 authentication keys to access twitter API\n",
    "* to connect as OAth handler or jump serever / revers proxy server\n",
    "    * consumer_key = \"8AO6OU5ubyi4XO47b1C7Sjdlz\"\n",
    "    * consumer_sec = \"FS1usPrfPolvjLXbwGka5N8TWkOZhUsdxGmmTwuO016koesUSt\"\n",
    "\n",
    "* from proxy server we need to connect\n",
    "    * access_token = \"1151573806680592384-OUFeUtpsRFZM6jQxl1AG99NEjlY0Kt\"\n",
    "    * access_token_sec = \"KKHmkHkDGVaDof8XK4fKKI52DmNl4vZlaXnx85WRfd4Lr\"\n",
    "\n",
    "\n",
    "**Expectations**\n",
    "* Text Cleaning and deriving insights to advise what can be the next steps for business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to connect to OAth handler or jump server/revers proxy server\n",
    "consumer_key = \"8AO6OU5ubyi4XO47b1C7Sjdlz\"\n",
    "consumer_sec = \"FS1usPrfPolvjLXbwGka5N8TWkOZhUsdxGmmTwuO016koesUSt\"\n",
    "\n",
    "#from proxy server we need to connect\n",
    "access_token = \"1151573806680592384-OUFeUtpsRFZM6jQxl1AG99NEjlY0Kt\"\n",
    "access_token_sec = \"KKHmkHkDGVaDof8XK4fKKI52DmNl4vZlaXnx85WRfd4Lr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to jump server of twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect from jump server to web server of twitter\n",
    "auth.set_access_token(access_token, access_token_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to API Strong server of twitter\n",
    "api_connect=tweepy.API(auth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0b023209574ea816c3923c83276d545ed0ec4acc5374302f44c761f6510ec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
